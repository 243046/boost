{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e02323",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d551e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa994a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = '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'\n",
    "usr = '243046'\n",
    "repo = 'boost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://{token}@github.com/{usr}/{repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65708074",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a28cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd content/boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df272e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c62b3a",
   "metadata": {},
   "source": [
    "# Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from wrappers.datasets_models_wrappers import DataModelsWrapper, DataModelsWrapperRandomSearch\n",
    "from wrappers.datasets_models_wrappers_nlp import DataModelsWrapperNLP, DataModelsWrapperNLPRandomSearch\n",
    "from data_processing.process_dataset import prepare_datasets_for_classification\n",
    "from data_processing.process_dataset_nlp import prepare_nlp_for_classification\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def run(param_dict, mode='randomized', tuner='hyperopt', scoring='accuracy'):\n",
    "    if mode == 'randomized':\n",
    "        model = DataModelsWrapperRandomSearch(param_dict, scoring=scoring)\n",
    "    elif mode == 'TPE':\n",
    "        model = DataModelsWrapper(param_dict, tuner=tuner, scoring=scoring)\n",
    "    model.fit()\n",
    "    all_results = model.all_datasets_results_\n",
    "    all_runtimes = model.all_datasets_runtimes_\n",
    "    results_for_plotting = model.results_for_plotting_\n",
    "    runtimes_for_plotting = model.runtimes_for_plotting_\n",
    "    return all_results, all_runtimes, results_for_plotting, runtimes_for_plotting\n",
    "\n",
    "\n",
    "def run_nlp(param_dict, mode='randomized', tuner='hyperopt', scoring='accuracy',\n",
    "            tfidf_kws={'ngram_range': (1, 2), 'min_df': 3, 'max_features': 10000}):\n",
    "    if mode == 'randomized':\n",
    "        model = DataModelsWrapperNLPRandomSearch(param_dict, scoring=scoring, tfidf_kws=tfidf_kws)\n",
    "    elif mode == 'TPE':\n",
    "        model = DataModelsWrapperNLP(param_dict, tuner=tuner, scoring=scoring, tfidf_kws=tfidf_kws)\n",
    "    model.fit()\n",
    "    all_results = model.all_datasets_results_\n",
    "    all_runtimes = model.all_datasets_runtimes_\n",
    "    results_for_plotting = model.results_for_plotting_\n",
    "    runtimes_for_plotting = model.runtimes_for_plotting_\n",
    "    return all_results, all_runtimes, results_for_plotting, runtimes_for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b55e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'mushrooms.csv': ('class', 'all', None),\n",
    "    'adult.csv': ('profit', [], None),\n",
    "    'churn.csv': ('Churn', [], None),\n",
    "    'creditcard.csv': ('Class', [], None),\n",
    "    'prostate.csv': ('target', [], None),\n",
    "    'leukemia.csv': ('target', [], None),\n",
    "    'weather_dataset.csv': ('target', [], 200)\n",
    "}\n",
    "\n",
    "X_1, y_1, X_2, y_2, X_3, y_3, X_4, y_4, X_5, y_5, X_6, y_6, X_7, y_7 = prepare_datasets_for_classification(d, data_path='data/')\n",
    "\n",
    "X_8, y_8 = prepare_nlp_for_classification(\n",
    "    dataset_name='imdb_dataset.csv',\n",
    "    text_column='review_cleared',\n",
    "    y_col='sentiment',\n",
    "    nrows=2000,\n",
    "    data_path='data/'\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [4]\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(), params),\n",
    "    'XGBoost': (XGBClassifier(reg_lambda=2, use_label_encoder=False, eval_metric='logloss', random_state=123), params),\n",
    "    'LightGBM': (LGBMClassifier(reg_lambda=2), params),\n",
    "    'CatBoost': (CatBoostClassifier(n_estimators=100, reg_lambda=2, verbose=False, random_state=123), params)\n",
    "}\n",
    "\n",
    "param_dict = {\n",
    "    'mushrooms': (X_1, y_1, models),\n",
    "    'adult': (X_2, y_2, models),\n",
    "    'churn': (X_3, y_3, models),\n",
    "    'credit card': (X_4, y_4, models),\n",
    "    'prostate': (X_5, y_5, models),\n",
    "    'leukemia': (X_6, y_6, models),\n",
    "    'weather': (X_7, y_7, models)\n",
    "}\n",
    "\n",
    "param_dict_nlp = {\n",
    "    'IMDB reviews': (X_8, y_8, models)\n",
    "}\n",
    "\n",
    "tfidf_kws = {'ngram_range': (1, 2), 'min_df': 3, 'max_features': 10000}\n",
    "\n",
    "all_results, all_runtimes, results_for_plotting, runtimes_for_plotting = run(param_dict=param_dict,\n",
    "                                                                             mode='randomized', scoring='accuracy')\n",
    "\n",
    "_, _, results_for_plotting_nlp, runtimes_for_plotting_nlp = run_nlp(param_dict=param_dict_nlp,\n",
    "                                                                    mode='randomized',\n",
    "                                                                    scoring='accuracy',\n",
    "                                                                    tfidf_kws=tfidf_kws\n",
    "                                                                    )\n",
    "\n",
    "all_results = pd.concat([results_for_plotting, results_for_plotting_nlp])\n",
    "all_runtimes = pd.concat([runtimes_for_plotting, runtimes_for_plotting_nlp])\n",
    "all_results.to_excel('results_colab/results_no_search.xlsx', index=False)\n",
    "all_runtimes.to_excel('results_colab/runtimes_no_search.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081b388",
   "metadata": {},
   "source": [
    "# Code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from ray import tune\n",
    "\n",
    "from wrappers.datasets_models_wrappers import DataModelsWrapper, DataModelsWrapperRandomSearch\n",
    "from data_processing.process_dataset import prepare_datasets_for_classification\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def run(param_dict, mode='TPE', tuner='hyperopt', scoring='accuracy'):\n",
    "    if mode == 'randomized':\n",
    "        model = DataModelsWrapperRandomSearch(param_dict, scoring=scoring)\n",
    "    elif mode == 'TPE':\n",
    "        model = DataModelsWrapper(param_dict, tuner=tuner, scoring=scoring)\n",
    "    model.fit()\n",
    "    all_results = model.all_datasets_results_\n",
    "    all_runtimes = model.all_datasets_runtimes_\n",
    "    results_for_plotting = model.results_for_plotting_\n",
    "    runtimes_for_plotting = model.runtimes_for_plotting_\n",
    "    return all_results, all_runtimes, results_for_plotting, runtimes_for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f53dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'mushrooms.csv': ('class', 'all', None),\n",
    "    'adult.csv': ('profit', [], None),\n",
    "    'churn.csv': ('Churn', [], None),\n",
    "    'creditcard.csv': ('Class', [], None)\n",
    "}\n",
    "\n",
    "X_1, y_1, X_2, y_2, X_3, y_3, X_4, y_4 = prepare_datasets_for_classification(d)\n",
    "\n",
    "boosting_params = {\n",
    "    'n_estimators': tune.choice([50, 100, 150]),\n",
    "    'learning_rate': tune.loguniform(0.01, 0.1)\n",
    "}\n",
    "xgb_params = {\n",
    "    'n_estimators': tune.choice([50, 100, 150]),\n",
    "    'learning_rate': tune.loguniform(0.01, 0.1)\n",
    "}\n",
    "lgbm_params = {\n",
    "    'n_estimators': tune.choice([50, 100, 150]),\n",
    "    'learning_rate': tune.loguniform(0.01, 0.1)\n",
    "}\n",
    "catboost_params = {\n",
    "    'n_estimators': tune.choice([50, 100, 150]),\n",
    "    'learning_rate': tune.loguniform(0.01, 0.1)\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(), boosting_params),\n",
    "    'XGBoost': (XGBClassifier(use_label_encoder=False,\n",
    "                             eval_metric='logloss', random_state=123), xgb_params),\n",
    "    'LightGBM': (LGBMClassifier(), lgbm_params),\n",
    "    'CatBoost': (CatBoostClassifier(verbose=False, random_state=123), catboost_params)\n",
    "}\n",
    "\n",
    "param_dict = {\n",
    "    'mushrooms': (X_1, y_1, models),\n",
    "    'adult': (X_2, y_2, models),\n",
    "    'churn': (X_3, y_3, models),\n",
    "    'credit card': (X_4, y_4, models)\n",
    "}\n",
    "\n",
    "all_results, all_runtimes, results_for_plotting, runtimes_for_plotting = run(param_dict=param_dict,\n",
    "                                                                             mode='TPE', scoring='accuracy')\n",
    "\n",
    "name = 'ordinary_TPE'\n",
    "results_for_plotting.to_excel(f'results/results_{name}.xlsx', index=False)\n",
    "runtimes_for_plotting.to_excel(f'results/runtimes_{name}.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boost",
   "language": "python",
   "name": "boost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
